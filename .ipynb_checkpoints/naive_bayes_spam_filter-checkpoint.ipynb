{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Naive Bayes Spam Filter\n",
    "\n",
    "In this project we build a classifier using a Naive Bayes algorithm to sort SMS messages into spam and non-spam. This is a guided project part of the Dataquest data science program.\n",
    "\n",
    "The goal is to build a filter that is at least 80% accurate. The spam filter was actually almost 99% accurate.\n",
    "\n",
    "The dataset used in this project was put together by Tiago A. Almeida and José María Gómez Hidalgo, downloaded from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "sms = pd.read_csv('SMSSpamCollection', sep='\\t', header = None, names = ['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     86.593683\n",
      "spam    13.406317\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#what percent is spam and ham ('non-spam')\n",
    "\n",
    "per_spam_ham = sms.Label.value_counts(normalize = True)*100\n",
    "print(per_spam_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that about 87% of the text messages is ham and 13% is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test sets\n",
    "Before writing the spam filter software, we will split the data into a training set and a test set. 80% of the dataset will be used for training and 20% will be used to test the spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize the dataset\n",
    "randomized = sms.copy()\n",
    "randomized = randomized.sample(frac = 1, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "#calculating index values to use for split\n",
    "training_index = round(len(randomized)*0.8)\n",
    "\n",
    "#splitting into training and test\n",
    "training = randomized[:training_index].reset_index(drop = True)\n",
    "test = randomized[training_index:].reset_index(drop = True)\n",
    "\n",
    "print(training.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: Label, dtype: float64\n",
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking the percentage of spam and ham in the training and test sets\n",
    "\n",
    "training_ham_spam = training.Label.value_counts(normalize = True)*100\n",
    "test_ham_spam = test.Label.value_counts(normalize = True)*100\n",
    "\n",
    "print(training_ham_spam)\n",
    "print(test_ham_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test sets have the same percentage of spam and ham, and the same as the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "We will need to clean the training data to get the relevant data for the spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training dataset before cleaning\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to remove all the non-words from the SMS column and make them all lowercase (so 'SECRET' is not different than 'secret')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4v/8q8s246j5t5_2qhs0c6ssd2m0000gn/T/ipykernel_52842/3603615211.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  training['SMS'] = training['SMS'].str.replace('\\W', ' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing non-word characters\n",
    "training['SMS'] = training['SMS'].str.replace('\\W', ' ')\n",
    "\n",
    "#changing to all lowercase\n",
    "training['SMS'] = training['SMS'].str.lower()\n",
    "\n",
    "#training set after cleaning\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a vocabulary \n",
    "\n",
    "#transform the SMS message into a list\n",
    "training['SMS'] = training['SMS'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                  [yep, by, the, pretty, sculpture]\n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2   ham                    [welp, apparently, he, retired]\n",
       "3   ham                                           [havent]\n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yep', 'by', 'the', 'pretty', 'sculpture']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for sms in training['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "print(vocabulary[:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the list to a set to remove duplicates, then back to list\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7,783 words in the training dataset vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The final training set\n",
    "We'll create a dictionary of the words in the SMS where each key is a unique word from the vocabulary and each value is a list the length of the training set. For example if the training set contained only three messages, and 'secret' appeared twice in the first message, once in the second message and not at all in the third message, then the dictionary entry for that word would be 'secret': [2,1,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training['SMS']) for unique_word in vocabulary}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sms in enumerate(training['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_clean = pd.concat([training, word_count], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>edward</th>\n",
       "      <th>pls</th>\n",
       "      <th>removed</th>\n",
       "      <th>weiyi</th>\n",
       "      <th>em</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>evrey</th>\n",
       "      <th>planet</th>\n",
       "      <th>warwick</th>\n",
       "      <th>support</th>\n",
       "      <th>mth</th>\n",
       "      <th>contact</th>\n",
       "      <th>musta</th>\n",
       "      <th>08700435505150p</th>\n",
       "      <th>palm</th>\n",
       "      <th>wherever</th>\n",
       "      <th>subscribe</th>\n",
       "      <th>snuggles</th>\n",
       "      <th>thinkin</th>\n",
       "      <th>reache</th>\n",
       "      <th>theacusations</th>\n",
       "      <th>fondly</th>\n",
       "      <th>somewhere</th>\n",
       "      <th>...</th>\n",
       "      <th>somewhat</th>\n",
       "      <th>entry</th>\n",
       "      <th>ls1</th>\n",
       "      <th>255</th>\n",
       "      <th>embarrassed</th>\n",
       "      <th>3qxj9</th>\n",
       "      <th>answers</th>\n",
       "      <th>amp</th>\n",
       "      <th>aeronautics</th>\n",
       "      <th>booking</th>\n",
       "      <th>mess</th>\n",
       "      <th>poly</th>\n",
       "      <th>wiv</th>\n",
       "      <th>idea</th>\n",
       "      <th>free</th>\n",
       "      <th>each</th>\n",
       "      <th>wiskey</th>\n",
       "      <th>lecturer</th>\n",
       "      <th>calld</th>\n",
       "      <th>cme</th>\n",
       "      <th>sometime</th>\n",
       "      <th>bruv</th>\n",
       "      <th>021</th>\n",
       "      <th>summers</th>\n",
       "      <th>heading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  edward  pls  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]       0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...       0    0   \n",
       "2   ham                    [welp, apparently, he, retired]       0    0   \n",
       "3   ham                                           [havent]       0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...       0    0   \n",
       "\n",
       "   removed  weiyi  em  chocolate  evrey  planet  warwick  support  mth  \\\n",
       "0        0      0   0          0      0       0        0        0    0   \n",
       "1        0      0   0          0      0       0        0        0    0   \n",
       "2        0      0   0          0      0       0        0        0    0   \n",
       "3        0      0   0          0      0       0        0        0    0   \n",
       "4        0      0   0          0      0       0        0        0    0   \n",
       "\n",
       "   contact  musta  08700435505150p  palm  wherever  subscribe  snuggles  \\\n",
       "0        0      0                0     0         0          0         0   \n",
       "1        0      0                0     0         0          0         0   \n",
       "2        0      0                0     0         0          0         0   \n",
       "3        0      0                0     0         0          0         0   \n",
       "4        0      0                0     0         0          0         0   \n",
       "\n",
       "   thinkin  reache  theacusations  fondly  somewhere  ...  somewhat  entry  \\\n",
       "0        0       0              0       0          0  ...         0      0   \n",
       "1        0       0              0       0          0  ...         0      0   \n",
       "2        0       0              0       0          0  ...         0      0   \n",
       "3        0       0              0       0          0  ...         0      0   \n",
       "4        0       0              0       0          0  ...         0      0   \n",
       "\n",
       "   ls1  255  embarrassed  3qxj9  answers  amp  aeronautics  booking  mess  \\\n",
       "0    0    0            0      0        0    0            0        0     0   \n",
       "1    0    0            0      0        0    0            0        0     0   \n",
       "2    0    0            0      0        0    0            0        0     0   \n",
       "3    0    0            0      0        0    0            0        0     0   \n",
       "4    0    0            0      0        0    0            0        0     0   \n",
       "\n",
       "   poly  wiv  idea  free  each  wiskey  lecturer  calld  cme  sometime  bruv  \\\n",
       "0     0    0     0     0     0       0         0      0    0         0     0   \n",
       "1     0    0     0     0     0       0         0      0    0         0     0   \n",
       "2     0    0     0     0     0       0         0      0    0         0     0   \n",
       "3     0    0     0     0     0       0         0      0    0         0     0   \n",
       "4     0    0     0     0     0       0         0      0    0         0     0   \n",
       "\n",
       "   021  summers  heading  \n",
       "0    0        0        0  \n",
       "1    0        0        0  \n",
       "2    0        0        0  \n",
       "3    0        0        0  \n",
       "4    0        0        0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the probability values\n",
    "The Naive Bayes alogrithm will need these probability value to classify the messages:\n",
    "\n",
    "(1) $ P(Spam|w_{1},w_{2},...,w_{n})\\propto P(Spam)\\cdot \\prod \\limits_{i=1}^n P(w_{i}|Spam) $\n",
    "\n",
    "(2) $ P(Ham|w_{1},w_{2},...,w_{n})\\propto P(Ham)\\cdot \\prod \\limits_{i=1}^n P(w_{i}|Ham) $\n",
    "\n",
    "\n",
    "We will need $P(Spam)$, $P(Ham)$, as well as the values for $ P(w_{i}|Spam)$ and $P(w_{i}|Ham) $\n",
    "\n",
    "(3) $ P(w_{i}|Spam) = \\frac{N_{w_{i}|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}$\n",
    "\n",
    "(4) $ P(w_{i}|Ham) = \\frac{N_{w_{i}|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the clean training set into spam and ham\n",
    "\n",
    "spam_messages = training_clean[training_clean['Label'] == 'spam']\n",
    "ham_messages = training_clean[training_clean['Label']=='ham']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13458950201884254\n"
     ]
    }
   ],
   "source": [
    "#calculating P(Spam)\n",
    "p_spam = len(spam_messages)/len(training_clean)\n",
    "print(p_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8654104979811574\n"
     ]
    }
   ],
   "source": [
    "#calculating P(Ham)\n",
    "p_ham = len(ham_messages)/len(training_clean)\n",
    "print(p_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Nspam is the number of words in all the spam messages (not unique words)\n",
    "num_s_words = spam_messages['SMS'].apply(len)\n",
    "num_spam= num_s_words.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nham is the number of words in all the ham messages (not unique words)\n",
    "num_h_words = ham_messages['SMS'].apply(len)\n",
    "num_ham = num_h_words.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nvocabulary is the number of unique words in the set\n",
    "num_vocabulary = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have calculated the constant terms $ P(Ham) $ and $ P(Spam) $ as well as $ N_{Spam}$, $ N_{Ham} $ and $ N_{Vocabulary}$. Now we need to find the parameters $ P(w_{i}|Spam) $ and $ P(w_{i}|Ham) $ using the equations (3) and (4) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing two dictionaries for parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "#calculating parameter values\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum() #spam_messages defined above\n",
    "    p_word_given_spam = (n_word_given_spam + alpha)/(num_spam + (alpha*num_vocabulary))\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum() #ham_messages defined above\n",
    "    p_word_given_ham = (n_word_given_ham + alpha)/(num_ham + (alpha*num_vocabulary))\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    '''    \n",
    "    message = a string\n",
    "    \n",
    "    ''' \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_spam = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "sample_ham = \"Sounds good, Tom, then see u there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify(sample_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(sample_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the spam filter\n",
    "The filter worked well on the sample text we used above, but we'll see now how well it works with the test dataset.\n",
    "\n",
    "We'll modify the classify function to return rather than print the result, we'll add this returned classification to a column in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding new column to the test set\n",
    "\n",
    "test['predicted'] = test['SMS'].apply(classify_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy\n",
    "\n",
    "$ Accuracy = \\frac{number of correctly classified messages}{total number of classified messages} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct =  1100\n",
      "incorrect=  14\n",
      "accuracy =  0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test.shape[0] #number of messages in the test set\n",
    "\n",
    "for row in test.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('correct = ', correct)\n",
    "print('incorrect= ', total - correct)\n",
    "accuracy = correct/total\n",
    "print('accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spam filter classified 1,1110 messages correctly and 14 messages incorrectly. It is 98.74% accurate. This is much more accurate than I had anticipated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going a bit further...\n",
    "Let's take a quick look at the 14 messages that were classifed incorrectly to see if anything jumps out as to why they were classified incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = test.loc[test['Label'] != test['predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Label                                                SMS  \\\n",
      "114  spam  Not heard from U4 a while. Call me now am here...   \n",
      "135  spam  More people are dogging in your area now. Call...   \n",
      "152   ham                  Unlimited texts. Limited minutes.   \n",
      "159   ham                                       26th OF JULY   \n",
      "284   ham                             Nokia phone is lovly..   \n",
      "293   ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
      "302   ham                   No calls..messages..missed calls   \n",
      "319   ham  We have sent JD for Customer Service cum Accou...   \n",
      "504  spam  Oh my god! I've found your number again! I'm s...   \n",
      "546  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
      "741  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
      "876  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
      "885  spam                                      2/2 146tf150p   \n",
      "953  spam  Hello. We need some posh birds and chaps to us...   \n",
      "\n",
      "                      predicted  \n",
      "114                         ham  \n",
      "135                         ham  \n",
      "152                        spam  \n",
      "159                        spam  \n",
      "284                        spam  \n",
      "293  needs human classification  \n",
      "302                        spam  \n",
      "319                        spam  \n",
      "504                         ham  \n",
      "546                         ham  \n",
      "741                         ham  \n",
      "876                         ham  \n",
      "885                         ham  \n",
      "953                         ham  \n"
     ]
    }
   ],
   "source": [
    "print(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlimited texts. Limited minutes.\n"
     ]
    }
   ],
   "source": [
    "print(incorrect.loc[152]['SMS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After reviewing the mislabeled emails, there's nothing that jumps out at me as to why they were mislabeled. I'd have to research this more to be able to make an educated guess.\n",
    "\n",
    "However I'll note that I was surprised by the degree of accuracy in the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
